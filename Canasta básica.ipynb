{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing libraries\n",
    "from datetime import date\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import xlrd #This library is necessary because of the the xls files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36 Edg/120.0.0.0\"}\n",
    "\n",
    "URL = \"https://www.inide.gob.ni/Home/canasta\"\n",
    "page = requests.get(URL, headers = headers,verify=False)\n",
    "Soup1 = BeautifulSoup(page.content, \"html.parser\")\n",
    "Soup2 = BeautifulSoup(Soup1.prettify(),\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = []\n",
    "for fila in Soup2.find_all(\"a\", href = True):\n",
    "    row.append(fila[\"href\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Getting the URLs data. Each URL redirects to xls or xlsx files\n",
    "cleaned_URL = []\n",
    "url_main = \"https://www.inide.gob.ni\"\n",
    "\n",
    "for i in row:\n",
    "    if i.startswith(\"/docs\"):\n",
    "        cleaned_URL.append(url_main + i)\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This function gets the month from the files. They repeat the same pattern so this approach can be useful\n",
    "\n",
    "def Month_Date(x):\n",
    "    Months = {\n",
    "    \"ene\":\"-01-01\",\n",
    "    \"feb\":\"-02-01\",\n",
    "    \"mar\":\"-03-01\",\n",
    "    \"abr\":\"-04-01\",\n",
    "    \"may\":\"-05-01\",\n",
    "    \"jun\":\"-06-01\",\n",
    "    \"jul\":\"-07-01\",\n",
    "    \"ago\":\"-08-01\",\n",
    "    \"sep\":\"-09-01\",\n",
    "    \"oct\":\"-10-01\",\n",
    "    \"nov\":\"-11-01\",\n",
    "    \"dic\":\"-12-01\"\n",
    "    }\n",
    "\n",
    "    Month = None\n",
    "    Text = x.split(\"/\")[-1]\n",
    "\n",
    "    for i in Months.keys():\n",
    "        if i in Text.lower():\n",
    "            Month = Months[i]\n",
    "            break\n",
    "        else:\n",
    "            continue\n",
    "    return Month\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Describing the column names for the dataframe\n",
    "columns_df = [\"Descripción de productos\", \"Unidad de Medida\", \"Cantidad Mensual de Consenso\", \"Precios\", \"Córdobas\", \"Fecha\"]\n",
    "\n",
    "## THis function extract, transforms and load the data into a dataframe\n",
    "def data_ETL (df,df_date = None):   \n",
    "    df = df.iloc[4:]\n",
    "    df = df.drop(\"Unnamed: 0\", axis = 1).dropna().reset_index(drop=True)\n",
    "    df[\"Fecha\"] = df_date\n",
    "    df.columns = columns_df\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Main Dataframe where data is loaded\n",
    "df = pd.DataFrame(columns = columns_df)\n",
    "\n",
    "## Getting the data, passing it through the functions and loading them to the dataframe\n",
    "for i in cleaned_URL:\n",
    "    try: \n",
    "        s = requests.get(i).content\n",
    "        df_date = i.split(\"/\")[-2][2:] + Month_Date(i)\n",
    "        df_new_data = pd.read_excel(s)\n",
    "        df_new_data = data_ETL(df_new_data, df_date)\n",
    "        df = pd.concat([df,df_new_data],ignore_index=True)\n",
    "    except:\n",
    "        print(\"Failed: \" + i )\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exporting to csv file\n",
    "df.to_csv(\"CB Data_ISO.csv\", encoding= \"ISO 8859-1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
